{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "datas = []\n",
    "with open(\"./diamonds.0.json\") as in_file:\n",
    "  datas = json.load(in_file)\n",
    "\n",
    "for i,d in enumerate(datas):\n",
    "  del datas[i][\"id\"]\n",
    "  datas[i][\"carat\"] = float(d[\"carat\"])\n",
    "  datas[i][\"depth\"] = float(d[\"depth\"])\n",
    "  datas[i][\"table\"] = float(d[\"table\"])\n",
    "  datas[i][\"price\"] = int(d[\"price\"])\n",
    "  datas[i][\"x\"] = float(d[\"x\"])\n",
    "  datas[i][\"y\"] = float(d[\"y\"])\n",
    "  datas[i][\"z\"] = float(d[\"z\"])\n",
    "\n",
    "datas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./diamonds.json', 'w') as out_file:\n",
    "  json.dump(datas, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "datas = []\n",
    "with open(\"./Los_Angeles_housing.json\") as in_file:\n",
    "  datas = json.load(in_file)\n",
    "\n",
    "for i,d in enumerate(datas):\n",
    "  datas[i][\"longitude\"] = float(d[\"longitude\"])\n",
    "  datas[i][\"latitude\"] = float(d[\"latitude\"])\n",
    "  datas[i][\"rooms\"] = float(d[\"rooms\"])\n",
    "  datas[i][\"bedrooms\"] = float(d[\"bedrooms\"])\n",
    "  datas[i][\"age\"] = int(float(d[\"age\"]))\n",
    "  datas[i][\"value\"] = int(d[\"value\"])\n",
    "\n",
    "datas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Los_Angeles_housing2.json', 'w') as out_file:\n",
    "  json.dump(datas, out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "\n",
    "list_height = []\n",
    "list_weight = []\n",
    "list_data = []\n",
    "\n",
    "body_data = []\n",
    "\n",
    "for fn in ['./ANSUR_MALE.csv', './ANSUR_FEMALE.csv']:\n",
    "  with open(fn) as in_file:\n",
    "    csv_reader = csv.DictReader(in_file)\n",
    "\n",
    "    for row in csv_reader:\n",
    "      list_height.append(int(row[\"Heightin\"]))\n",
    "      list_weight.append(int(row[\"Weightlbs\"]))\n",
    "      list_data.append((\n",
    "        int(row[\"Age\"]), int(row[\"Heightin\"]), int(row[\"Weightlbs\"])\n",
    "      ))\n",
    "\n",
    "      body_data.append({\n",
    "        \"age\": int(row[\"Age\"]),\n",
    "        \"height\": int(row[\"Heightin\"]),\n",
    "        \"weight\": int(row[\"Weightlbs\"])\n",
    "      })\n",
    "\n",
    "print(len(list_data), len(body_data))\n",
    "\n",
    "random.shuffle(list_height)\n",
    "random.shuffle(list_weight)\n",
    "random.shuffle(list_data)\n",
    "random.shuffle(body_data)\n",
    "\n",
    "# with open('./list_height.json', 'w') as out_file:\n",
    "#   json.dump(list_height, out_file)\n",
    "\n",
    "# with open('./list_weight.json', 'w') as out_file:\n",
    "#   json.dump(list_weight, out_file)\n",
    "\n",
    "# with open('./list_age_height_weight.json', 'w') as out_file:\n",
    "#   json.dump(list_data, out_file)\n",
    "\n",
    "with open('./ansur_age_height_weight.json', 'w') as out_file:\n",
    "  json.dump(body_data, out_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "\n",
    "body_data = []\n",
    "\n",
    "for fn in ['./ANSUR_MALE.csv', './ANSUR_FEMALE.csv']:\n",
    "  with open(fn) as in_file:\n",
    "    csv_reader = csv.DictReader(in_file)\n",
    "\n",
    "    for row in csv_reader:\n",
    "      body_data.append({\n",
    "        \"age\": int(row[\"Age\"]),\n",
    "        \"gender\": \"M\" if row[\"Gender\"] == \"Male\" else \"F\",\n",
    "        \"height\": int(row[\"Heightin\"]),\n",
    "        \"weight\": int(row[\"Weightlbs\"]),\n",
    "        \"span\": int(row[\"span\"]),\n",
    "        \"stature\": int(row[\"stature\"]),\n",
    "        \"ear\": {\n",
    "          \"breadth\": int(row[\"earbreadth\"]),\n",
    "          \"length\": int(row[\"earlength\"]),\n",
    "          \"protrusion\": int(row[\"earprotrusion\"])\n",
    "        },\n",
    "        \"foot\": {\n",
    "          \"breadth\": int(row[\"footbreadthhorizontal\"]),\n",
    "          \"length\": int(row[\"footlength\"])\n",
    "        },\n",
    "        \"hand\": {\n",
    "          \"breadth\": int(row[\"handbreadth\"]),\n",
    "          \"length\": int(row[\"handlength\"]),\n",
    "          \"palm\": int(row[\"palmlength\"])\n",
    "        },\n",
    "        \"head\": {\n",
    "          \"breadth\": int(row[\"headbreadth\"]),\n",
    "          \"length\": int(row[\"headlength\"]),\n",
    "          \"height\": int(row[\"mentonsellionlength\"]),\n",
    "          \"top\": int(row[\"tragiontopofhead\"]),\n",
    "        },\n",
    "        \n",
    "      })\n",
    "\n",
    "print(len(body_data))\n",
    "\n",
    "random.shuffle(body_data)\n",
    "\n",
    "with open('./ansur_wk02.json', 'w') as out_file:\n",
    "  json.dump(body_data, out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "shark_data = []\n",
    "\n",
    "with open(\"./global-shark-attack.csv\", encoding=\"utf-8-sig\") as in_file:\n",
    "  csv_reader = csv.DictReader(in_file, delimiter=\";\")\n",
    "\n",
    "  for row in csv_reader:\n",
    "    shark_data.append({\n",
    "      \"date\": row[\"Date\"],\n",
    "      \"year\": int(row[\"Year\"]) if row[\"Year\"] != \"\" else 0,\n",
    "      \"country\": row[\"Country\"],\n",
    "      # \"gender\": 0 if row[\"Sex \"] == \"F\" else 1,\n",
    "      \"gender\": row[\"Sex \"],\n",
    "      \"age\": int(float(row[\"Age\"])) if row[\"Age\"] != \"\" else 0,\n",
    "      \"fatal\": row[\"Fatal (Y/N)\"] == \"Y\",\n",
    "      \"shark\": row[\"Species \"].lower().replace(\"shark\", \"\").strip()\n",
    "    })\n",
    "\n",
    "# print(len(shark_data), print(shark_data[0]))\n",
    "# print(shark_data[:10])\n",
    "\n",
    "with open('./shark_attack_2.json', 'w') as out_file:\n",
    "  json.dump(shark_data, out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "from random import sample\n",
    "\n",
    "json_data = []\n",
    "\n",
    "feature_exclude = [\"Aircraft Type\",\n",
    "  'Aircraft Make',\n",
    "  'Aircraft Model',\n",
    "  'Aircraft Mass',\n",
    "  'Engine Make',\n",
    "  'Engine Model',\n",
    "  'Engines',\n",
    "  'Engine Type',\n",
    "  'Engine1 Position',\n",
    "  'Engine2 Position',\n",
    "  'Engine3 Position',\n",
    "  'Engine4 Position',\n",
    "  'FAA Region',\n",
    "  'Warning Issued',\n",
    "  'Engine1 Strike',\n",
    "  'Engine1 Damage',\n",
    "  'Engine2 Strike',\n",
    "  'Engine2 Damage',\n",
    "  'Engine3 Strike',\n",
    "  'Engine3 Damage',\n",
    "  'Engine4 Strike',\n",
    "  'Engine4 Damage',\n",
    "  'Engine Ingested',\n",
    "  'Wing or Rotor Strike',\n",
    "  'Wing or Rotor Damage'\n",
    "  ]\n",
    "\n",
    "with open(\"./bird_strikes.00.csv\", encoding=\"utf-8\") as in_file:\n",
    "  with open('./bird_strikes.csv', 'w', newline='') as out_file:\n",
    "    csv_reader = csv.DictReader(in_file)\n",
    "    csv_writer = None\n",
    "\n",
    "    for row in csv_reader:\n",
    "      engine_strike = \"0\"\n",
    "      engine_damage = \"0\"\n",
    "      for i in range(1, 5):\n",
    "        engine_strike = \"1\" if row[\"Engine%d Strike\" % i] == \"1\" else engine_strike\n",
    "        engine_damage = \"1\" if row[\"Engine%d Damage\" % i] == \"1\" else engine_damage\n",
    "\n",
    "      row[\"Engine Strike\"] = engine_strike\n",
    "      row[\"Engine Damage\"] = engine_damage\n",
    "\n",
    "      row[\"Wing Strike\"] = row['Wing or Rotor Strike']\n",
    "      row[\"Wing Damage\"] = row['Wing or Rotor Damage']\n",
    "\n",
    "      for f in feature_exclude:\n",
    "        del row[f]\n",
    "\n",
    "      if csv_writer == None:\n",
    "        csv_writer = csv.DictWriter(out_file, fieldnames=list(row.keys()))\n",
    "        csv_writer.writeheader()\n",
    "      csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "    # json_data.append({\n",
    "    #   k:v for k,v in row.items()\n",
    "    # })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_out = sample(json_data, k=10000)\n",
    "\n",
    "len(json_data_out), min([int(r['Incident Year']) for r in json_data_out]), max([int(r['Incident Year']) for r in json_data_out])\n",
    "\n",
    "with open('./bird_accidents.json', 'w') as out_file:\n",
    "  json.dump(json_data_out, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "from random import sample\n",
    "\n",
    "json_data = []\n",
    "\n",
    "with open(\"./diamonds.csv\", encoding=\"utf-8\") as in_file:\n",
    "  csv_reader = csv.DictReader(in_file)\n",
    "\n",
    "  for row in csv_reader:\n",
    "    json_data.append({\n",
    "      \"carat\": float(row[\"carat\"]),\n",
    "      \"depth\": float(row[\"depth\"]),\n",
    "      \"table\": float(row[\"table\"]),\n",
    "      \"x\": float(row[\"x\"]),\n",
    "      \"y\": float(row[\"y\"]),\n",
    "      \"z\": float(row[\"z\"]),\n",
    "      \"cut\": row[\"cut\"],\n",
    "      \"color\": row[\"color\"],\n",
    "      \"clarity\": row[\"clarity\"],\n",
    "      \"price\": int(row[\"price\"]),\n",
    "    })\n",
    "\n",
    "data_sample = sample(json_data, k=16384)\n",
    "\n",
    "split_index = 1024\n",
    "data_test = data_sample[:split_index]\n",
    "data_train = data_sample[split_index:]\n",
    "\n",
    "len(data_test), len(data_train)\n",
    "\n",
    "with open('./diamonds.json', 'w') as out_file:\n",
    "  json.dump(data_train, out_file)\n",
    "\n",
    "with open('./diamonds-test.json', 'w') as out_file:\n",
    "  json.dump(data_test, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "json_data = []\n",
    "\n",
    "with open(\"./iris.csv\", encoding=\"utf-8\") as in_file:\n",
    "  csv_reader = csv.DictReader(in_file)\n",
    "\n",
    "  for row in csv_reader:\n",
    "    json_data.append({\n",
    "      k.replace(\"Cm\",\"\"):v for k,v in row.items()\n",
    "    })\n",
    "\n",
    "with open('./iris.json', 'w') as out_file:\n",
    "  json.dump(json_data, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "json_data = []\n",
    "\n",
    "with open(\"./mushrooms.csv\", encoding=\"utf-8\") as in_file:\n",
    "  csv_reader = csv.DictReader(in_file)\n",
    "\n",
    "  for row in csv_reader:\n",
    "    json_data.append({ k:v for k,v in row.items() })\n",
    "\n",
    "with open('./mushrooms.json', 'w') as out_file:\n",
    "  json.dump(json_data, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "json_data = []\n",
    "\n",
    "with open(\"./i94_traffic_volume.csv\", encoding=\"utf-8\") as in_file:\n",
    "  csv_reader = csv.DictReader(in_file)\n",
    "\n",
    "  for row in csv_reader:\n",
    "    del row[\"holiday\"]\n",
    "    json_data.append({ k.replace(\"_1h\",\"\").replace(\"_all\",\"\").replace(\"_main\",\"\"):v for k,v in row.items() })\n",
    "\n",
    "with open('./i94_traffic_volume.json', 'w') as out_file:\n",
    "  json.dump(json_data, out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import sys\n",
    "\n",
    "csv.field_size_limit(sys.maxsize//10)\n",
    "\n",
    "json_data = {}\n",
    "\n",
    "with open(\"./DSLCC/DSL3-DEV.txt\", encoding=\"utf-8\") as in_file:\n",
    "  csv_reader = csv.DictReader(in_file, delimiter=\"\\t\")\n",
    "\n",
    "  for row in csv_reader:\n",
    "    if row[\"lang\"] == None:\n",
    "      continue\n",
    "    if row[\"lang\"] not in json_data:\n",
    "      json_data[row[\"lang\"]] = []\n",
    "    json_data[row[\"lang\"]].append(row[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:len(v) for k,v in json_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
